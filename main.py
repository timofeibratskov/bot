import openai
import base64
import os
import requests
from keyboard import kb
from aiogram import Bot, Dispatcher, executor, types

from config import OPENAI_TOKEN, BOT_TOKEN
from gtts import gTTS


# Initialize OpenAI client
openai_client = openai.AsyncOpenAI(api_key=OPENAI_TOKEN)
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot)
api_key = OPENAI_TOKEN

# Create a thread and assistant
thread = None
assistant = None


async def create_thread_and_assistant():
    global thread, assistant
    assistant = await openai_client.beta.assistants.create(
        name="–Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥",
        instructions="–≤—ã –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –¥–æ–∫—Ç–æ—Ä-–Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥.–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å",
        tools=[{"type": "code_interpreter"}],
        model="gpt-4-1106-preview",
    )
    thread = await openai_client.beta.threads.create()


async def process_question(question):
    global thread, assistant
    if not thread or not assistant:
        await create_thread_and_assistant()

    # Create a user message in the thread
    message = await openai_client.beta.threads.messages.create(
        thread_id=thread.id,
        role="user",
        content=question,
    )

    # Run the thread and poll for completion
    run = await openai_client.beta.threads.runs.create_and_poll(
        thread_id=thread.id,
        assistant_id=assistant.id,
        instructions="–ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –æ—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–æ—Ä–æ—Ç–∫–æ –∏ –Ω–µ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º!",
    )

    if run.status == "completed":
        # Get the list of messages in the thread
        messages = await openai_client.beta.threads.messages.list(thread_id=thread.id)

        # Extract and return the assistant's response
        response = messages.data[0].content[0].text.value

        return response

    return None


def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')


# start command
@dp.message_handler(commands=['start'])
async def send_welcome(message: types.Message):
    await message.reply(
        f"–ü—Ä–∏–≤–µ—Ç, {message.from_user.full_name}!\n–Ø –±–æ—Ç-–Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥ üçΩ \n –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ –µ–¥—ã –∏ —è –ø–æ–¥—Å—á–∏—Ç–∞—é –∫–∞–ª–æ—Ä–∏–∏ –∏–ª–∏ –∑–∞–¥–∞–π –º–Ω–µ –≤–æ–ø—Ä–æ—Å,\n –∫—Å—Ç–∞—Ç–∏,–µ—Å–ª–∏ –ª–µ–Ω—å –ø–∏—Å–∞—Ç—å –º–æ–∂–µ—à—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ) ",
        reply_markup=kb
    )


# handler for photo
@dp.message_handler(content_types=['photo', 'document'])
async def handle_photo_message(message: types.Message):
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        await message.photo[-1].download(destination_file='photo.jpg')
        image_path = 'photo.jpg'
        base64_image = encode_image(image_path)
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": "gpt-4-turbo",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "—Å–∫–æ–ª—å–∫–æ –∏—Ç–æ–≥–æ–≤–∞—è —Å—É–º–º–∞ –±–∂—É –∏ –∫–∞–ª–æ—Ä–∏–π –≤ –µ–¥–µ –Ω–∞ —Ñ–æ—Ç–æ?"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
        }

        response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
        await message.reply(response.json()['choices'][0]['message']['content'])
    except Exception as e:
        await message.reply("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ.")
        print(e)
    finally:
        os.remove(image_path)


# handler for answers
@dp.message_handler()
async def get_answer(message: types.Message):
    try:
        response = await process_question(message.text)
        await message.reply(response)
    except Exception as e:
        await message.reply("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")
        print(e)


# handler for voice
@dp.message_handler(content_types=['voice'])
async def handle_voice(message: types.Message):
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–æ–ª–æ—Å–æ–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
        file_id = message.voice.file_id
        file = await bot.get_file(file_id)
        file_path = file.file_path
        destination = f'{file_id}.ogg'
        # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        await bot.download_file(file_path, destination)

        audio_file = open(destination, "rb")
        translation = await openai_client.audio.translations.create(
            model="whisper-1",
            file=audio_file
        )
        audio_file.close()
        text_from_audio = translation.text
        response_in_text = await process_question(text_from_audio)
        tts = gTTS(response_in_text, lang='ru')
        audio_f = 'temp_audioanswer.ogg'
        tts.save(audio_f)
        with open(audio_f, 'rb') as f:
            await bot.send_voice(message.from_user.id, f)
            f.close()
            os.remove(destination)
            os.remove(audio_f)
    except Exception as e:
        await message.reply("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
        print(e)


if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
